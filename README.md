# Oil Analysis Data Product

**AI-Powered Oil Analysis Pipeline for Mining Equipment**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-green.svg)](https://openai.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)

---

## ğŸ¯ Overview

This repository contains the **Oil Analysis Data Product** that processes mining equipment oil analysis data from raw laboratory results (Bronze layer) to analysis-ready insights (Gold layer). The system applies statistical threshold detection (Stewart Limits) and AI-powered maintenance recommendations to support fleet management decisions.

**Core Question Answered**: *"How is my fleet performing based on oil analysis?"*

---

## ğŸ—ï¸ System Capabilities

### Data Processing Pipeline

```
Raw Lab Data â†’ Harmonization â†’ Statistical Analysis â†’ Classification â†’ AI Recommendations â†’ Gold Layer
  (Bronze)        (Silver)         (Limits)          (Status)        (Insights)         (Output)
```

### Key Features

- âœ… **Multi-Lab Integration**: Processes data from ALS and Finning laboratories
- âœ… **Multi-Client Support**: Handles CDA and EMIN client data independently
- âœ… **Stewart Limits**: Dynamic statistical thresholds (90th, 95th, 98th percentiles)
- âœ… **Multi-Level Classification**: Essay â†’ Report â†’ Component â†’ Machine status hierarchy
- âœ… **AI Recommendations**: GPT-4 powered maintenance insights for abnormal conditions
- âœ… **Parallel Processing**: 18-worker AI generation for fast execution
- âœ… **Docker Ready**: Containerized deployment with docker-compose

---

## ğŸ“Š Data Flow

### Input (Bronze Layer)
- **Location**: `data/oil/raw/`
- **Formats**: Excel (Finning), Parquet (ALS)
- **Content**: Raw laboratory oil analysis results

### Processing (Silver Layer)
- **Location**: `data/oil/processed/`
- **Transformations**:
  - Name normalization and standardization
  - Missing value handling
  - Data quality filtering (minimum 100 samples)
  - Stewart Limits calculation

### Output (Gold Layer)
- **Location**: `data/oil/processed/`
- **Files**:
  - `cda_summary.json`: Complete CDA client analysis
  - `emin_summary.json`: Complete EMIN client analysis
  - `stewart_limits.json`: Reference thresholds

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- OpenAI API key (for AI recommendations)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd oil-analysis

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### Running the Pipeline

```bash
# Run complete pipeline
python main.py
```

### Using Docker

```bash
# Build and run with docker-compose
docker-compose up

# Or build manually
docker build -f Dockerfile.backend -t oil-analysis .
docker run -e OPENAI_API_KEY=your_key oil-analysis
```

---

## ğŸ“ Repository Structure

```
oil-analysis/
â”œâ”€â”€ config/                 # Configuration
â”‚   â”œâ”€â”€ settings.py         # Environment settings
â”‚   â”œâ”€â”€ logging_config.py   # Logging setup
â”‚   â””â”€â”€ users.py            # User credentials (for future auth)
â”‚
â”œâ”€â”€ data/oil/               # Data layers
â”‚   â”œâ”€â”€ raw/                # Bronze: Source files
â”‚   â”‚   â”œâ”€â”€ cda/            # CDA lab results
â”‚   â”‚   â””â”€â”€ emin/           # EMIN lab results
â”‚   â”œâ”€â”€ processed/          # Silver & Gold: Processed data
â”‚   â””â”€â”€ to_consume/         # Future: External consumption
â”‚
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/               # Data handling
â”‚   â”‚   â”œâ”€â”€ loaders.py      # Read lab files
â”‚   â”‚   â”œâ”€â”€ transformers.py # Bronze â†’ Silver
â”‚   â”‚   â”œâ”€â”€ exporters.py    # Gold layer export
â”‚   â”‚   â”œâ”€â”€ schemas.py      # Data models
â”‚   â”‚   â””â”€â”€ validators.py   # Data quality checks
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/         # Business logic
â”‚   â”‚   â”œâ”€â”€ stewart_limits.py       # Threshold calculation
â”‚   â”‚   â”œâ”€â”€ classification.py       # Status classification
â”‚   â”‚   â”œâ”€â”€ aggregations.py         # Machine-level rollup
â”‚   â”‚   â””â”€â”€ name_normalization.py   # Standardization
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/                 # AI integration
â”‚   â”‚   â”œâ”€â”€ recommendation_service.py
â”‚   â”‚   â”œâ”€â”€ prompts.py      # AI prompts
â”‚   â”‚   â””â”€â”€ parallel_executor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/           # Orchestration
â”‚   â”‚   â”œâ”€â”€ full_pipeline.py        # Main pipeline
â”‚   â”‚   â”œâ”€â”€ bronze_to_silver.py     # Layer 1 â†’ 2
â”‚   â”‚   â””â”€â”€ silver_to_gold.py       # Layer 2 â†’ 3
â”‚   â”‚
â”‚   â””â”€â”€ utils/              # Common utilities
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ date_utils.py
â”‚       â””â”€â”€ file_utils.py
â”‚
â”œâ”€â”€ docs/                   # Documentation
â”‚   â””â”€â”€ PROJECT_OVERVIEW.md # Detailed guide
â”‚
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â””â”€â”€ run_pipeline.py
â”‚
â”œâ”€â”€ notebooks/              # Jupyter exploration
â”‚   â””â”€â”€ explore_oil_full.ipynb
â”‚
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile.backend      # Docker image
â”œâ”€â”€ docker-compose.yml      # Container orchestration
â””â”€â”€ README.md               # This file
```

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Data Configuration
DATA_ROOT=./data/oil

# Processing Configuration
MAX_WORKERS=18  # Parallel AI generation threads

# Logging
LOGS_DIR=./logs
```

### Settings

Edit `config/settings.py` to configure:
- Client list (default: `["cda", "emin"]`)
- Data paths
- Processing parameters

---

## ğŸ“Š Classification System

### Essay-Level Classification

Individual chemical tests are compared against Stewart Limits:

- **Normal**: Below 90th percentile
- **Marginal**: 90th-95th percentile (1 point)
- **Condenatorio**: 95th-98th percentile (3 points)
- **CrÃ­tico**: Above 98th percentile (5 points)

### Report-Level Classification

Aggregate essay points for each oil sample:

- **Normal**: Total < 3 points
- **Alerta**: 3-4 points
- **Anormal**: â‰¥ 5 points

### Machine-Level Classification

Rollup component statuses for fleet units:

- **Normal**: Component scores < 2
- **Alerta**: Component scores 2-3
- **Anormal**: Component scores â‰¥ 4

---

## ğŸ¤– AI Integration

### Model Configuration

- **Model**: GPT-4o-mini
- **Temperature**: 0.9
- **Max Tokens**: ~500 (150 words)
- **Parallel Workers**: 18

### AI Recommendation Strategy

AI is called **only for non-Normal reports** to optimize costs:
- Normal reports: Generic "no anomalies" message
- Alert/Abnormal reports: Full AI analysis with:
  - Root cause identification
  - Specific corrective actions
  - Follow-up recommendations
  - Urgency indicators

### Cost Optimization

- **Without optimization**: 100% of reports â†’ ~$0.05 Ã— 100 = $5.00
- **With optimization**: 30% of reports â†’ ~$0.05 Ã— 30 = $1.50
- **Savings**: 70% cost reduction

---

## ğŸ“ˆ Output Schema

### Gold Layer Structure (JSON)

```json
{
  "sampleId": "CDA_001_2024-01-15",
  "client": "cda",
  "unitId": "CDA_001",
  "machineName": "camion",
  "machineModel": "789D",
  "componentName": "motor diesel",
  "sampleDate": "2024-01-15",
  "reportStatus": "Anormal",
  "essaySum": 6,
  "machineStatus": "Alerta",
  "totalNumericStatus": 3,
  "aiRecommendation": "Se detecta concentraciÃ³n elevada de Hierro...",
  "essays": {
    "Hierro": {
      "value": 55.2,
      "status": "Condenatorio",
      "threshold": 45.0,
      "points": 3
    },
    "Cobre": {
      "value": 28.1,
      "status": "Marginal",
      "threshold": 25.0,
      "points": 1
    }
  }
}
```

---

## ğŸ”§ Development

### Running Tests

```bash
# Run full pipeline test
python main.py
```

### Exploring Data

```bash
# Launch Jupyter notebook
jupyter notebook notebooks/explore_oil_full.ipynb
```

### Adding New Clients

1. Add raw data files to `data/oil/raw/<client_name>/`
2. Update `config/settings.py`:
   ```python
   clients = ["cda", "emin", "new_client"]
   ```
3. Run pipeline: `python main.py`

---

## ğŸ“š Documentation

- **[Project Overview](docs/PROJECT_OVERVIEW.md)**: High-level system description and data architecture
- **Business Logic**: Detailed Stewart Limits methodology (coming soon)
- **Data Contracts**: Schema specifications (coming soon)
- **Deployment Guide**: Production deployment (coming soon)

---

## ğŸ³ Docker Deployment

### Development

```bash
docker-compose up
```

### Production

```bash
# Build image
docker build -f Dockerfile.backend -t oil-analysis:latest .

# Run container
docker run -d \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --name oil-analysis \
  oil-analysis:latest
```

### Scheduled Execution

Use cron or Kubernetes CronJob for periodic execution:

```bash
# Run daily at 2 AM
0 2 * * * docker start oil-analysis
```

---

## ğŸ“Š Typical Processing Metrics

- **Input**: 50-100 raw lab reports per week
- **Processing Time**: 2-5 minutes (full pipeline)
- **AI Generation**: ~30 seconds for 100 reports (parallel)
- **Output Size**: 1-5 MB per client summary

---

## ğŸ” Security

- **API Keys**: Store in `.env` file (never commit)
- **Data Access**: Gold layer files contain processed data only
- **Client Isolation**: Separate output files per client

---

## ğŸ¤ Data Mesh Integration

This oil analysis data product is designed to integrate with broader data mesh architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Oil Analysis        â”‚ â† This Repository
â”‚ (Bronze â†’ Gold)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€ Output: cda_summary.json
           â”œâ”€ Output: emin_summary.json
           â””â”€ Output: stewart_limits.json
                      â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Fusion Service       â”‚ (Separate Repo)
           â”‚ (Cross-domain)       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Dashboard/BI Tools   â”‚ (Separate Repo)
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Interface**: JSON files in gold layer folder serve as data product output

---

## ğŸ“ Support

For questions or issues:
- Review documentation in `docs/`
- Check logs in `logs/` folder
- Examine sample data in `notebooks/`

---

## ğŸ”„ Version

**v1.0.0** - Oil Analysis Data Product (Data Mesh Architecture)

- Multi-client support (CDA, EMIN)
- Stewart Limits implementation
- AI-powered recommendations
- Docker deployment ready
- Gold layer output for data mesh integration
