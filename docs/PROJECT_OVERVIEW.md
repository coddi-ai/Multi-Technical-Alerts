# Oil Analysis Data Product

**AI-Powered Oil Analysis System for Mining Equipment Fleet Management**

---

## ğŸ¯ Purpose

This data product provides automated oil analysis processing for mining equipment, transforming raw laboratory test results into actionable maintenance insights. The system processes data from bronze (raw) to gold (analysis-ready) layers, applying statistical threshold detection and AI-powered recommendations.

The primary goal is to answer: **"How is my fleet performing based on oil analysis?"** by transforming raw chemical essay data into clear, prioritized maintenance insights.

---

## ğŸ—ï¸ What This System Does

### 1. **Unified Data Processing**
Consolidates oil analysis data from multiple laboratory providers (ALS and Finning) across different clients (EMIN and CDA), creating a standardized data model that enables cross-fleet analysis and comparison.

### 2. **Statistical Threshold Detection (Stewart Limits)**
Establishes dynamic alert thresholds for each chemical essay based on historical performance data, accounting for variations across different machine types and components. These limits define three severity levels:
- **Normal**: Within expected operating parameters
- **Alert**: Marginal values requiring monitoring
- **Anormal**: Critical values requiring immediate action

### 3. **Multi-Level Status Classification**
Implements a hierarchical assessment model:

```
Essay â†’ Report â†’ Component â†’ Machine/Unit
```

- **Essay Level**: Individual chemical test results (Fe, Cu, Si, etc.) compared against Stewart Limits
- **Report Level**: Aggregate assessment of all essays in a single oil sample
- **Component Level**: Status of individual equipment parts (engine, transmission, hydraulics, etc.)
- **Machine Level**: Overall fleet unit health based on all monitored components

### 4. **AI-Generated Maintenance Recommendations**
Integrates with OpenAI GPT-4 to provide:
- Contextual interpretation of abnormal readings
- Root cause analysis (contamination, wear, degradation, etc.)
- Specific maintenance actions (component inspection, oil change, filter replacement, etc.)
- Urgency classification and follow-up intervals

The AI system is trained with domain-specific examples from mechanical engineering experts specializing in mining equipment.

### 5. **Gold Layer Output**
Produces analysis-ready data files for downstream consumption (dashboards, reporting tools, data warehouses):
- Processed samples with classifications
- Machine status summaries
- Component health assessments
- AI recommendations

---

## ğŸ“Š Data Architecture

### Bronze â†’ Silver â†’ Gold Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Lab Data   â”‚  Bronze Layer: Immutable source files
â”‚  (CDA / EMIN)   â”‚  - Excel files (Finning Lab)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Parquet files (ALS Lab)
         â”‚
         â–¼ [Harmonization]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Unified Oil   â”‚  Silver Layer: Standardized schema
â”‚    Samples      â”‚  - Consistent column names
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Normalized values
         â”‚           - Validated data types
         â”‚
         â–¼ [Statistical Analysis]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stewart Limits  â”‚  Threshold Calculation
â”‚  (JSON/Parquet) â”‚  - Per client/machine/component/essay
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - 90th, 95th, 98th percentiles
         â”‚
         â–¼ [Classification]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Classified    â”‚  Gold Layer: Analysis-ready
â”‚    Reports      â”‚  - Essay â†’ Report â†’ Machine status
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - AI recommendations
         â”‚           - Severity metrics
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gold Layer     â”‚  Final Output for Consumption
â”‚  Output Files   â”‚  - CDA summary, EMIN summary
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Stewart Limits reference
```

---

## ğŸš€ Key Features

- âœ… **Multi-Source Data Integration**: Handles different lab formats and structures
- âœ… **Adaptive Thresholds**: Statistical limits based on historical performance
- âœ… **Context-Aware Analysis**: Machine/component-specific classifications
- âœ… **AI-Powered Insights**: Expert-level maintenance recommendations
- âœ… **Scalable Processing**: Parallel AI generation (18 workers)
- âœ… **Data Quality Controls**: Automated validation and filtering
- âœ… **Gold Layer Export**: Ready for dashboard consumption

---

## ğŸ“ Repository Structure

```
oil-analysis/
â”œâ”€â”€ config/              # Configuration files
â”‚   â”œâ”€â”€ settings.py      # Environment settings
â”‚   â””â”€â”€ logging_config.py
â”œâ”€â”€ data/                # Data layers
â”‚   â””â”€â”€ oil/
â”‚       â”œâ”€â”€ raw/         # Bronze: Source files
â”‚       â”œâ”€â”€ processed/   # Silver: Standardized data
â”‚       â””â”€â”€ to_consume/  # Gold: Analysis-ready
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ data/            # Data loading & transformation
â”‚   â”œâ”€â”€ processing/      # Business logic
â”‚   â”œâ”€â”€ ai/              # AI recommendations
â”‚   â”œâ”€â”€ pipeline/        # Orchestration
â”‚   â””â”€â”€ utils/           # Common utilities
â”œâ”€â”€ docs/                # Documentation
â”œâ”€â”€ scripts/             # Utility scripts
â”œâ”€â”€ notebooks/           # Exploration notebooks
â”œâ”€â”€ main.py              # Pipeline entry point
â””â”€â”€ requirements.txt     # Python dependencies
```

---

## ğŸ“š Documentation

- **[Business Logic & Implementation](BUSINESS_LOGIC.md)**: Detailed explanation of Stewart Limits, classification system, and AI integration
- **[Data Contracts](DATA_CONTRACTS.md)**: Schema specifications and transformation rules
- **[Deployment Guide](DEPLOYMENT.md)**: Setup and deployment instructions

---

## ğŸ”§ Technology Stack

- **Language**: Python 3.11+
- **Data Processing**: Pandas, NumPy
- **AI Integration**: OpenAI GPT-4
- **Containerization**: Docker
- **Data Formats**: Excel, Parquet, JSON

---

## ğŸ¯ Use Cases

### For Fleet Managers
- Identify machines requiring urgent attention
- Prioritize maintenance resources
- Track fleet health trends

### For Maintenance Teams
- Receive specific corrective action recommendations
- Understand root causes of equipment issues
- Schedule preventive maintenance

### For Data Engineers (Downstream Consumers)
- Consume gold layer data for dashboards
- Integrate with business intelligence tools
- Build cross-domain analytics

---

## ğŸ”„ Data Mesh Integration

This oil analysis data product is designed to integrate with a larger data mesh architecture:

```
Oil Analysis (This Repo) â†’ Gold Layer Output
                              â†“
                         Fusion Service
                              â†“
                        Dashboard/BI Tools
```

**Input**: Raw oil analysis files from laboratories  
**Output**: Classified samples, machine statuses, AI recommendations  
**Interface**: JSON/Parquet files in gold layer folder

---

## ğŸ“Š Output Data Products

### 1. CDA Summary (`cda_summary.json`)
Complete gold layer data for CDA client including:
- All processed samples with classifications
- Machine-level status aggregations
- Component health assessments
- AI recommendations

### 2. EMIN Summary (`emin_summary.json`)
Complete gold layer data for EMIN client (same structure as CDA)

### 3. Stewart Limits (`stewart_limits.json`)
Reference thresholds for all essays across all machine/component combinations

---

## ğŸš¦ Status Classifications

### Report Level
- **Normal**: essaySum < 3 points
- **Alerta**: 3 â‰¤ essaySum < 5 points
- **Anormal**: essaySum â‰¥ 5 points

### Machine Level
- **Normal**: totalStatus < 2 points
- **Alerta**: 2 â‰¤ totalStatus < 4 points
- **Anormal**: totalStatus â‰¥ 4 points

---

## ğŸ“ˆ Typical Processing Volumes

- **Raw Samples**: ~50-100 reports/week per client
- **Processing Time**: ~2-5 minutes for full pipeline
- **AI Recommendations**: Generated for ~30% of samples (non-Normal only)
- **Output Size**: ~1-5 MB per client summary file

---

## ğŸ” Configuration

Key environment variables:
- `OPENAI_API_KEY`: OpenAI API key for AI recommendations
- `DATA_ROOT`: Root path for data files
- `MAX_WORKERS`: Parallel workers for AI generation (default: 18)

---

## ğŸ“ Quick Start

1. **Run Pipeline**:
   ```bash
   python main.py
   ```

2. **Using Docker**:
   ```bash
   docker-compose up
   ```

3. **Check Output**:
   ```bash
   data/oil/processed/
   â”œâ”€â”€ cda_summary.json
   â”œâ”€â”€ emin_summary.json
   â””â”€â”€ stewart_limits.json
   ```

For detailed instructions, see [DEPLOYMENT.md](DEPLOYMENT.md).
